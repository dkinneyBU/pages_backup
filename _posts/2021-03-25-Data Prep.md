---
layout: post
title:  "Data Preparation"
author: David Kinney
categories: [ projects, LSI ]
image: ../images/openweather.PNG
description: ""
---
## An exercise in Data Preparation and the Open Weather Map...

I'm drawn to investigating climate change, so when I saw that one of the suggested APIs was the **Open Weather Map** site I zeroed in. Unfortunately, long-term historical data requires a paid membership, but for this exercise I felt that using the free subscription and utilizing a 5-day, 3-hour interval dataset of my hometown of Atlanta would be applicable for the exercise.

The first step was finding the **city ID** for Atlanta. Open Weather Map has a downloadable JSON file with all the cities and ID's. I downloaded that and searched for `name='Atlanta'` to retrieve the ID. After registering for a free API key, I had everything I needed to send a request to the API to get the weather data.

**Transformation and Cleaning**

After retrieving the dataset I displayed the first few rows. Initial exploration revealed a few items that could be immediately addressed:

* There were some columns that were not relevant to analysis; I dropped them.
* A number of columns were themselves JSON objects (in one case, a list of a dictionary item). I expanded those out into individual columns.
* Temperatures were in Kelvin; I converted them to Fahrenheit.
* Replace some column names with more user-friendly titles.
* Some columns had NaN values, which might bear further investigation.

This Jupyter notebook shows the sequence of steps I took to perform this process, as well as others that cropped up along the way.

**Importance and Relevance**

In the few years I've been doing data analysis and science, I have yet to come across a dataset that is clean and ready for use "out of the box". In this particular use case, being able to use those columns that were JSON objects would be virtually impossible. Converting each key to its own column made the data much more understandable. I don't feel that it's an exaggeration to say that data preparation is required in virtually every Data Science project, whether on a large scale or small.

My repo for this project can be found [here](https://github.com/dkinneyBU/data-prep).
